---
title: "Analy 502 Project"
author: "Ayushi Yadav, Monika Kommareddy, Pratik Pachpute, Zhenjun Wang"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
master <- read.csv("/Users/ayushiyadav/Desktop/Harrisburg/SEM 1/ANLY 502 - Analytical Methods/FINAL PROJECT/final data (2).csv") 
master <- master[-52, ] # removing the grand total row
library(ggplot2)
library(ppcor)
library(QuantPsyc)
library(moments)
library(reshape)
library(reshape2)
library(rvest)
library(MOTE)
library(mice)
library(Hmisc)
library(corrplot)
library(cocor)
library(pwr)
library(psych)
library(scales)
library(maps)
library(mapproj)
library(stargazer)
options(scipen = 999)

```
### Data Screening

# The values for all continuous columns are the average values. We are renaming to visualize the corrplot to determine the correlations
```{r}
names(master) <- c("States", "Smokers", "Full_service_restaurants", "Fast_food_expenditures", "no_car", "eating_fruits&veggi", "Lbs_per_meat&poultry", "obesity", "fitness_facilities", "Lbs_per_solidfats", "household_income",
"No_exercise", "Chip&pretzel_sales_tax&vending", "Lbs_per_sweetsnacks", "Gals_soft_drinks", "Fast_food_restaurants",
"Lbs_prepared_meals", "price_sweetened_drinks", "Poverty_rate",
"PriceRatio_fruit/sweet_snacks", "PriceRatio_fruit/savory_snacks",
"PriceRatio_green_leafy/starchyVegi",
"Students_reducedprice_lunch_eligible")

colnames(master)
```

#Selecting the columns with correlations more than 0.6
```{r, dpi= 700, fig.width= 8}
correlations = cor(master[ , -1], use = "pairwise.complete.obs")
symnum(correlations)
corrplot(correlations)
```

```{r}
master1 <- master[, c(2,5,8,11,12,15,19)]
correlations1 = cor(master1)
symnum(correlations1)
colnames(master1)
summary(master1)
```

# 1.Accuracy
```{r}
```

# 2. Missing Data
```{r}
percentmiss = function(x) { (sum(is.na(x)) /length(x)) *100}
missing = apply(master1, 1, percentmiss)
table(missing)
```

# 3.Outliers
```{r}
#Leverage
summary(master1)
output = lm(obesity ~ Smokers + no_car + household_income + No_exercise + Gals_soft_drinks + Poverty_rate, data = master1) 
summary(output)


#Leverage
k=6
leverage = hatvalues(output)
cutleverage = ((2*6)+2) / nrow(master1)
cutleverage


badleverage = as.numeric(leverage > cutleverage) 
badleverage
table(badleverage)



```

```{r}
#Cooks
k=6
cooks = cooks.distance(output)
cutcooks = 4 / (nrow(master1) - 6 - 1) 
cutcooks
badcooks = as.numeric(cooks > cutcooks)
table(badcooks)


```

```{r}
#mahal

mahal = mahalanobis(master1, colMeans(master1, na.rm = TRUE), cov(master1, use = "pairwise.complete.obs"))
cutoff = qchisq(0.999, ncol(master1))
cutoff
badmahal = as.numeric(mahal > cutoff) 
table(badmahal)


totalout = badmahal + badleverage + badcooks
table(totalout)

```

```{r}
noout = subset(master1, totalout < 2)
summary(noout)
```
 
```{r}
#running a no outliers regression
output = lm(obesity ~ Smokers + no_car + household_income + No_exercise + Gals_soft_drinks + Poverty_rate, data = noout)
summary(output)
```
# Assumptions  

```{r}
# 1. Additivity

correl = cor(noout, use = "pairwise.complete.obs")
correl
 
symnum(correl)
pairs.panels(noout)

## Correlation for all other variables:
# install.packages("psych")

pairs.panels(master[2:6])
pairs.panels(master[7:12])
pairs.panels(master[13:18])
pairs.panels(master[19:23])

#Excluding Income 
colnames(noout)
final_noout <- noout[ , -4]
summary(final_noout)

```


```{r}
#setitng up assumptions
# install.packages("moments")
library(moments)
#Running regresion on the final_noout dataset
output1 =  lm(obesity ~ Smokers + no_car + No_exercise + Gals_soft_drinks + Poverty_rate, data = final_noout)
summary(output1)
standardized = rstudent(output1)
fitted = scale(output1$fitted.values)

# 2. Normality
hist(standardized)
skewness(final_noout)
  
kurtosis(noout)              
```

```{r}
# 3. Linearity
qqnorm(standardized)
abline(0,1)
```

```{r}
# 4. Homogenity and Homoscadesticity
plot(fitted, standardized)
abline(0,0)
abline(v = 0)
```
#The residuals look evenly spread above and below the X axis and all the way across the x axis. Hence
#we can say that we have met the condition for homogeneity.

```{r}
states = map_data("state")

master$region <- NA

# # create a new variable region for state
master$region = tolower(master$States)

# #merging the datasets
states = merge(states, master, by="region", all.x=T)

statenames = states %>% group_by(region) %>%
  summarise(
    long = mean(range(long)), 
    lat = mean(range(lat)), 
    group = mean(group), 
    obesity = mean(obesity))
```


```{r}
#Plotting the graph of most obese states
ggplot(states, aes(x = long, y = lat, group = group, fill = obesity)) +
  geom_polygon(color = "white",show.legend = T) +
  scale_fill_gradient(name = "Percent", low = "#40E0D0", high = "#008080", guide = "colorbar", na.value="black", breaks = pretty_breaks(n = 5)) +
  labs(title="Adult Obesity Rates according to states",x = "Longitude",y = "Latitude") +
  coord_map() +
  geom_text(data=statenames, aes(x = long, y = lat, label = region), size=3) +
  theme_classic()
```

```{r}
# final real regression 
# Simultaneous Linear Regression
model1 = lm(obesity ~ Smokers + no_car + No_exercise + Gals_soft_drinks + Poverty_rate, data = final_noout)
summary(model1)

```

```{r}
model2 = lm(obesity ~ Poverty_rate, data = final_noout)
summary(model2)
```


```{r}
model3 = lm(obesity ~ Smokers + no_car + No_exercise + Gals_soft_drinks, data = final_noout)
summary(model3)
```

```{r}
# Calculating Beta
# install.packages("QuantPsyc")

library(QuantPsyc)
lm.beta(model)
       
      

```

```{r}

#Calculating the effect size of predictors to determines which predictor is stronger
#partial correlation(pr)
library(ppcor)
partials = pcor(final_noout, method = "pearson")
partials
partials$estimate ^ 2  # to ensure the pr is squared
```



```{r}
#plotting
library(ggplot2)
cleanup = theme(panel.grid.major = element_blank(),
                panel.grid.minor = element_blank(),
                panel.background = element_blank(),
                axis.line = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))


# Getting final fitted values( yhat values, same like data screening but without standardizing)
fitted = model$fitted.values

#making the plot
scatter = ggplot(final_noout, aes(fitted, obesity))
scatter + cleanup + geom_point(color = "orchid4") + geom_smooth(method = "lm", color = "orchid4", fill = "orchid") + xlab("smokers+no_car+No_exercise+Gals_soft_drinks+Poverty_rate") +
ylab("Obesity rate")

```

#Hypothesis Testing

We will test whether if one of the predictors in our model Smoking is significanlty related to the obesity rate
We will test the hypothesis at a significance level of 0.05.
We will perform t-testing to get a t-statistic score
#1 Obesity vs Smoking 
H0: b1(smoking) = 0
H1: b1(smoking) =! 0

```{r}
model = lm(obesity ~ Smokers + no_car + No_exercise + Gals_soft_drinks + Poverty_rate, data = final_noout)
stargazer(model, type = "text")
```


# Prediction 
We will predict new obesity values given a 25% increase in our significant variables. 

```{r}
#creating new val
train_1 <- final_noout
test_1 <- 1.05*final_noout

predict_train <- predict(model1, newdata = train_1)
ggplot() + geom_point(aes(x=train_1$obesity,y=predict_train), size=3,colour = "Blue") +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
        scale_y_continuous(labels = label_number(suffix = " K", scale = 1e-3))+
        scale_x_continuous(labels = label_number(suffix = " K", scale = 1e-3))+
        ggtitle("Actual Obesity vs Predicted Obesity Rates - Train Data")+
        theme(plot.title = element_text(hjust = 0.5))+
        xlab("Actual Obesity Rate") + ylab("Predicted Obesity Rate") +
        theme_classic()

predict_test <- predict(model1, newdata = test_1)
ggplot() + 
        geom_point(aes(x=test_1$obesity,y=predict_test), size =3, colour = "Blue") +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
        scale_y_continuous(labels = label_number(suffix = " K", scale = 1e-3))+
        scale_x_continuous(labels = label_number(suffix = " K", scale = 1e-3))+
        ggtitle("Actual Obesity vs Predicted Obesity Rates- Test Data")+
        theme(plot.title = element_text(hjust = 0.5))+
        xlab("Actual Obesity Rate") + ylab("Predicted Obesity Rate")+
        theme_classic()

MAPE(predict_test,test_1$obesity)
RMSE(predict_test,test_1$obesity)
```

